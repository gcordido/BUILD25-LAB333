{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e791117f",
   "metadata": {},
   "source": [
    "# Notebook¬†4: End‚Äëto‚ÄëEnd App Development üõ†Ô∏è  \n",
    "![Catering Diagram](https://source.unsplash.com/featured/?catering,diagram)\n",
    "\n",
    "## Scenario Overview  \n",
    "*Customer selects menu items (tags: price, cuisine, dietary).*  \n",
    "We must: 1Ô∏è‚É£¬†scale recipes ‚Üí ingredients list,‚ÄØ2Ô∏è‚É£¬†schedule prep,‚ÄØ3Ô∏è‚É£¬†produce place‚Äëcards.\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "  A[Customer Order] --> B[Reasoning Model<br>Plan];\n",
    "  B --> C[GPT‚Äë4o Mini<br>Create Prompts];\n",
    "  C --> D[Worker GPTs<br>Shopping List & Schedule];\n",
    "  D --> E[Output Docs]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461a9bf1",
   "metadata": {},
   "source": [
    "## Recipe¬†7¬†‚Äî¬†Metaprompting the Plan\n",
    "### 1Ô∏è‚É£¬†Goal\n",
    "Use **o4‚Äëmini** to break high‚Äëlevel plan into JSON subtasks and craft GPT prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7536b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "sample_order = {\n",
    "    \"delivery_time\":\"2025-05-15T18:00:00\",\n",
    "    \"guests\":40,\n",
    "    \"items\":[\"Veg Biryani\",\"Paneer Tikka\",\"Gulab Jamun\"]\n",
    "}\n",
    "meta_prompt = f\"\"\"You are a senior catering planner.\n",
    "Given the JSON order below, output JSON with keys:\n",
    "tasks[], gpt_prompt_for_each_task.\n",
    "Order: {json.dumps(sample_order)}\"\"\"\n",
    "plan = pretty_chat_openai(\"o4-mini\", meta_prompt, temperature=0.2).choices[0].message.content\n",
    "print(plan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a290afc7",
   "metadata": {},
   "source": [
    "**Take‚Äëaway** ‚Äì Reasoning model produces *meta‚Äëprompts* that downstream GPT models execute.\n",
    "\n",
    "**Exercise:** add a cost‚Äëestimation task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27c28dd",
   "metadata": {},
   "source": [
    "## Recipe¬†8¬†‚Äî¬†Model Chaining in Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ccde82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast, openai, time\n",
    "plan_dict = ast.literal_eval(plan)  # simplistic parse\n",
    "results={}\n",
    "for task, prompt in zip(plan_dict[\"tasks\"], plan_dict[\"gpt_prompt_for_each_task\"]):\n",
    "    print(\"‚ñ∂\", task)\n",
    "    res = pretty_chat_openai(\"gpt-4o-mini\", prompt)\n",
    "    results[task] = res.choices[0].message.content\n",
    "# Store or post‚Äëprocess results...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8136076d",
   "metadata": {},
   "source": [
    "**Take‚Äëaway** ‚Äì Decouple planning (reasoning) from execution (GPT).\n",
    "\n",
    "**Exercise:** Insert verification step between chain calls."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
