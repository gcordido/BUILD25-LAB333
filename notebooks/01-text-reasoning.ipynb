{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de69cdc1-399e-47e6-ae0c-b2fb7b80c78c",
   "metadata": {},
   "source": [
    "# Get Started With Reasoning Models\n",
    "\n",
    "This is your first introduction to working with reasoning models, code-first. In this notebook, we'll primarily use the o4-mini model. However, we will also explore the `o1` model briefly, to understand how the API works for both. Use [this table](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/reasoning?tabs=python-secure%2Cpy#api--feature-support) for the latest information on supported features. And visit the [Reasoning Models](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/reasoning?tabs=python%2Cpy) documentation page for API details and code snippets. Here's a quick summary for convenience:\n",
    "\n",
    "<br/>\n",
    "\n",
    "| Characteristic | o1 | o4-mini |\n",
    "|:--- |:---|:---|\n",
    "| Developer Messages    | ✅ | ✅ |\n",
    "| Structured Outputs    | ✅ | ✅ |\n",
    "| Context Window Input  | 200K | 100K |\n",
    "| Context Window Output | 200K | 100K |\n",
    "| Reasoning Effort      | ✅ | ✅ |\n",
    "| Vision Support        | ✅ | ✅ |\n",
    "| Chat Completions API  | ✅ | ✅ |\n",
    "| Responses API         | ✅ |    |\n",
    "| Functions / Tools     | ✅ | ✅ |\n",
    "| max_completion_tokens | ✅ |    |\n",
    "| System messages       | ✅ | ✅ |\n",
    "| Reasoning summary     | ✅ | |\n",
    "| Streaming             | ✅ | |\n",
    "| Model Card | [o4-mini](https://ai.azure.com/explore/models/o4-mini/version/2025-04-16/registry/azure-openai) | [o1](https://ai.azure.com/explore/models/o1/version/2024-12-17/registry/azure-openai)  |\n",
    "| api_version | 2025-04-01-preview | 2025-03-01-preview |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86f57c1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Quickstart\n",
    "\n",
    "In this section, we'll do a quick check to make sure we have the right dependencies installed. We'll also test both o1 and o4-mini models but we'll primarily use the `o4-mini` unless explicitly stated otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249c08a8",
   "metadata": {},
   "source": [
    "### 1.1 Install Python Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae52d0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and Upgrade Pip\n",
    "!pip install --upgrade pip --quiet\n",
    "\n",
    "# Install Required Packages\n",
    "!pip install -q openai azure-identity python-dotenv --quiet\n",
    "\n",
    "# You may need to updated your OpenAI Python library\n",
    "!pip install openai --upgrade --quiet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2aec38",
   "metadata": {},
   "source": [
    "### 1.2 Check Env Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023c321d-b6af-42eb-b17b-1155e8cc4a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "if not os.getenv(\"AZURE_OPENAI_ENDPOINT\"):\n",
    "    print(\"Missing env: AZURE_OPENAI_ENDPOINT\")\n",
    "elif not os.getenv(\"AZURE_OPENAI_KEY\"):\n",
    "    print(\"Missing env: AZURE_OPENAI_KEY\")\n",
    "else: \n",
    "    print(\"Azure OpenAI endpoint and key are set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e43dfb4",
   "metadata": {},
   "source": [
    "### 1.3 Define Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020bab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print stats for the response\n",
    "def pretty_print(response, response_time):\n",
    "    \"\"\"\n",
    "    Prints the response details in a formatted manner.\n",
    "    Args:\n",
    "        response (openai.types.chat.chat_completion.ChatCompletion): The response object containing the generated completion.\n",
    "        response_time (float): The time taken to get the response.\n",
    "    \"\"\"\n",
    "    print(\".........................\")\n",
    "    print(f\"Response time: {response_time:.2f} seconds\")\n",
    "    print(f\"Total Tokens: {response.usage.total_tokens}\")\n",
    "    print(f\"Prompt Tokens: {response.usage.prompt_tokens}\")\n",
    "    print(f\"Completion Tokens: {response.usage.completion_tokens}\")\n",
    "    print(f\"Reasoning Tokens: {response.usage.completion_tokens_details.reasoning_tokens}\")\n",
    "    print(f\"Output Tokens: {response.usage.total_tokens - response.usage.completion_tokens_details.reasoning_tokens}\")\n",
    "    print(f\"\\nResponse:\\n {response.choices[0].message.content}\")\n",
    "    print(f\".........................\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8017cf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openai import AzureOpenAI\n",
    "import time\n",
    "\n",
    "# Chat with o1\n",
    "def o1_chat(prompt=\"hi\", reasoning_level=\"medium\", developer_message=\"You are a helpful assistant\"):\n",
    "    \"\"\"\n",
    "    Sends a chat completion request to the Azure OpenAI API o1 model.\n",
    "    Args:\n",
    "        prompt (str): The input prompt to generate a response for.\n",
    "        reasoning_level (str): The reasoning effort level ('low', 'medium', 'high').\n",
    "        developer_message (str): The developer message to set the context for the assistant.\n",
    "    Returns:\n",
    "        response (openai.types.chat.chat_completion.ChatCompletion): The response object containing the generated completion.\n",
    "    \"\"\"\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "        api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "        api_version=\"2025-04-01-preview\"\n",
    "    )\n",
    "    try:\n",
    "        request_time = time.time()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"o1\",\n",
    "            messages=[\n",
    "                {\"role\": \"developer\", \"content\": developer_message},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            max_completion_tokens=5000,\n",
    "            reasoning_effort=reasoning_level\n",
    "        )\n",
    "        response_time = time.time() - request_time\n",
    "        pretty_print(response, response_time)\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15e040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat with o4_mini\n",
    "def o4mini_chat(prompt=\"hi\", reasoning_level=\"medium\", developer_message=\"You are a helpful assistant\", response_format=None):\n",
    "    \"\"\"\n",
    "    Sends a chat completion request to the Azure OpenAI API o4-mini model.\n",
    "    Args:\n",
    "        prompt (str): The input prompt to generate a response for.\n",
    "        reasoning_level (str): The reasoning effort level ('low', 'medium', 'high').\n",
    "        developer_message (str): The developer message to set the context for the assistant.\n",
    "        response_format (BaseModel, optional): The expected structured output format for the response.\n",
    "    Returns:\n",
    "        response (openai.types.chat.chat_completion.ChatCompletion): The response object containing the generated completion.\n",
    "    \"\"\"\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "        api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "        api_version=\"2025-04-01-preview\"\n",
    "    )\n",
    "    try:\n",
    "        request_time = time.time()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"o4-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"developer\", \"content\": developer_message},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            max_completion_tokens=5000,\n",
    "            reasoning_effort=reasoning_level,\n",
    "            response_format=response_format\n",
    "        )\n",
    "        response_time = time.time() - request_time\n",
    "        pretty_print(response, response_time)\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e070d28",
   "metadata": {},
   "source": [
    "## 2.Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af7677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test o1\n",
    "response = o1_chat(\n",
    "    prompt=\"How many p's in hippopotamus?\",\n",
    "    reasoning_level=\"medium\",\n",
    "    developer_message=\"You are a helpful assistant.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23f18a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test o4mini\n",
    "response = o4mini_chat(\n",
    "    prompt=\"How many p's in hippopotamus?\",\n",
    "    reasoning_level=\"low\",\n",
    "    developer_message=\"You are a helpful assistant.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fd3791",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Let's Prompt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d7b58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------\n",
    "# MATH EXAMPLE\n",
    "# -------------------\n",
    "response = o4mini_chat(\n",
    "    prompt=\"A train travels at 60 mph. How long does it take to travel 90 miles?\",\n",
    "    reasoning_level=\"low\",\n",
    "    developer_message=\"You are a math tutor. Explain the solution\"\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e20849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------\n",
    "#  MATH REASONING\n",
    "# -------------------\n",
    "prompt = \"Jane has twice as many apples as Tom. Together they have 18 apples. How many does each person have?\"\n",
    "response = o4mini_chat(prompt)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb580ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------\n",
    "#  SCIENCE REASONING\n",
    "# -------------------\n",
    "prompt = \"Why does a metal spoon feel colder than a wooden spoon when left in the same room?\"\n",
    "response = o4mini_chat(prompt)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d52a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------\n",
    "#  MULTI-STEP PLANNING\n",
    "# -------------------\n",
    "prompt = \"Design a basic weekly study schedule to learn Python in 6 weeks, assuming 1 hour per weekday.\"\n",
    "response = o4mini_chat(prompt)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba29ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# CONSTRAINT-BASED SCHEDULING\n",
    "# --------------------------------\n",
    "prompt = \"Three employees—Alex, Sam, and Riley—must each work one 4-hour shift today. Only Alex and Riley can work before noon, and Sam can’t work past 4 PM. Create a valid schedule.\"\n",
    "response = o4mini_chat(prompt)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3f9135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------\n",
    "# TRY YOUR OWN\n",
    "# -------------------\n",
    "\n",
    "# Write your own prompt here\n",
    "prompt = \"\"  \n",
    "\n",
    "# Change these if you want to experiment\n",
    "reasoning_level = \"medium\"\n",
    "developer_message = \"You are a helpful assistant.\"\n",
    "response = o4mini_chat(prompt, reasoning_level, developer_message)\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
