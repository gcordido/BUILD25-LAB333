{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de69cdc1-399e-47e6-ae0c-b2fb7b80c78c",
   "metadata": {},
   "source": [
    "# Get Started With Reasoning Models\n",
    "\n",
    "This is your first introduction to working with reasoning models, code-first. In this notebook, we'll primarily use the o4-mini model. However, we will also explore the `o1` model briefly, to understand how the API works for both. Use [this table](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/reasoning?tabs=python-secure%2Cpy#api--feature-support) for the latest information on supported features. And visit the [Reasoning Models](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/reasoning?tabs=python%2Cpy) documentation page for API details and code snippets. Here's a quick summary for convenience:\n",
    "\n",
    "<br/>\n",
    "\n",
    "| Characteristic | o1 | o4-mini |\n",
    "|:--- |:---|:---|\n",
    "| Developer Messages    | ✅ | ✅ |\n",
    "| Structured Outputs    | ✅ | ✅ |\n",
    "| Context Window Input  | 200K | 100K |\n",
    "| Context Window Output | 200K | 100K |\n",
    "| Reasoning Effort      | ✅ | ✅ |\n",
    "| Vision Support        | ✅ | ✅ |\n",
    "| Chat Completions API  | ✅ | ✅ |\n",
    "| Responses API         | ✅ |    |\n",
    "| Functions / Tools     | ✅ | ✅ |\n",
    "| max_completion_tokens | ✅ |    |\n",
    "| System messages       | ✅ | ✅ |\n",
    "| Reasoning summary     | ✅ | |\n",
    "| Streaming             | ✅ | |\n",
    "| Model Card | [o4-mini](https://ai.azure.com/explore/models/o4-mini/version/2025-04-16/registry/azure-openai) | [o1](https://ai.azure.com/explore/models/o1/version/2024-12-17/registry/azure-openai)  |\n",
    "| api_version | 2025-04-01-preview | 2025-03-01-preview |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86f57c1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Quickstart\n",
    "\n",
    "In this section, we'll do a quick check to make sure we have the right dependencies installed. We'll also test both o1 and o4-mini models but we'll primarily use the `o4-mini` unless explicitly stated otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249c08a8",
   "metadata": {},
   "source": [
    "### 1.1 Install Python Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae52d0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and Upgrade Pip\n",
    "!pip install --upgrade pip --quiet\n",
    "\n",
    "# Install Required Packages\n",
    "!pip install -q openai azure-identity python-dotenv --quiet\n",
    "\n",
    "# You may need to updated your OpenAI Python library\n",
    "!pip install openai --upgrade --quiet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2aec38",
   "metadata": {},
   "source": [
    "### 1.2 Check Env Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023c321d-b6af-42eb-b17b-1155e8cc4a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "if not os.getenv(\"AZURE_OPENAI_ENDPOINT\"):\n",
    "    print(\"Missing env: AZURE_OPENAI_ENDPOINT\")\n",
    "elif not os.getenv(\"AZURE_OPENAI_KEY\"):\n",
    "    print(\"Missing env: AZURE_OPENAI_KEY\")\n",
    "else: \n",
    "    print(\"Azure OpenAI endpoint and key are set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e43dfb4",
   "metadata": {},
   "source": [
    "### 1.3 Define Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020bab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print stats for the response\n",
    "def pretty_print(response, response_time):\n",
    "    \"\"\"\n",
    "    Prints the response details in a formatted manner.\n",
    "    Args:\n",
    "        response (openai.types.chat.chat_completion.ChatCompletion): The response object containing the generated completion.\n",
    "        response_time (float): The time taken to get the response.\n",
    "    \"\"\"\n",
    "    print(\".........................\")\n",
    "    print(f\"Response time: {response_time:.2f} seconds\")\n",
    "    print(f\"Total Tokens: {response.usage.total_tokens}\")\n",
    "    print(f\"Prompt Tokens: {response.usage.prompt_tokens}\")\n",
    "    print(f\"Completion Tokens: {response.usage.completion_tokens}\")\n",
    "    print(f\"Reasoning Tokens: {response.usage.completion_tokens_details.reasoning_tokens}\")\n",
    "    print(f\"Output Tokens: {response.usage.total_tokens - response.usage.completion_tokens_details.reasoning_tokens}\")\n",
    "    print(f\"\\nResponse:\\n {response.choices[0].message.content}\")\n",
    "    print(f\".........................\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8017cf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openai import AzureOpenAI\n",
    "import time\n",
    "\n",
    "# Chat with o1\n",
    "def o1_chat(prompt=\"hi\", reasoning_level=\"medium\", developer_message=\"You are a helpful assistant\"):\n",
    "    \"\"\"\n",
    "    Sends a chat completion request to the Azure OpenAI API o1 model.\n",
    "    Args:\n",
    "        prompt (str): The input prompt to generate a response for.\n",
    "        reasoning_level (str): The reasoning effort level ('low', 'medium', 'high').\n",
    "        developer_message (str): The developer message to set the context for the assistant.\n",
    "    Returns:\n",
    "        response (openai.types.chat.chat_completion.ChatCompletion): The response object containing the generated completion.\n",
    "    \"\"\"\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "        api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "        api_version=\"2025-04-01-preview\"\n",
    "    )\n",
    "    try:\n",
    "        request_time = time.time()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"o1\",\n",
    "            messages=[\n",
    "                {\"role\": \"developer\", \"content\": developer_message},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            max_completion_tokens=5000,\n",
    "            reasoning_effort=reasoning_level\n",
    "        )\n",
    "        response_time = time.time() - request_time\n",
    "        pretty_print(response, response_time)\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d15e040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat with o4_mini\n",
    "def o4mini_chat(prompt=\"hi\", reasoning_level=\"medium\", developer_message=\"You are a helpful assistant\", response_format=None):\n",
    "    \"\"\"\n",
    "    Sends a chat completion request to the Azure OpenAI API o4-mini model.\n",
    "    Args:\n",
    "        prompt (str): The input prompt to generate a response for.\n",
    "        reasoning_level (str): The reasoning effort level ('low', 'medium', 'high').\n",
    "        developer_message (str): The developer message to set the context for the assistant.\n",
    "        response_format (BaseModel, optional): The expected structured output format for the response.\n",
    "    Returns:\n",
    "        response (openai.types.chat.chat_completion.ChatCompletion): The response object containing the generated completion.\n",
    "    \"\"\"\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "        api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "        api_version=\"2025-04-01-preview\"\n",
    "    )\n",
    "    try:\n",
    "        request_time = time.time()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"o4-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"developer\", \"content\": developer_message},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            max_completion_tokens=5000,\n",
    "            reasoning_effort=reasoning_level,\n",
    "            response_format=response_format\n",
    "        )\n",
    "        response_time = time.time() - request_time\n",
    "        pretty_print(response, response_time)\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e070d28",
   "metadata": {},
   "source": [
    "## 2.Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3af7677c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................\n",
      "Response time: 3.09 seconds\n",
      "Total Tokens: 307\n",
      "Prompt Tokens: 25\n",
      "Completion Tokens: 282\n",
      "Reasoning Tokens: 256\n",
      "Output Tokens: 51\n",
      "\n",
      "Response:\n",
      " There are 3 p’s in \"hippopotamus.\"\n",
      ".........................\n"
     ]
    }
   ],
   "source": [
    "# Test o1\n",
    "response = o1_chat(\n",
    "    prompt=\"How many p's in hippopotamus?\",\n",
    "    reasoning_level=\"medium\",\n",
    "    developer_message=\"You are a helpful assistant.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d23f18a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................\n",
      "Response time: 3.58 seconds\n",
      "Total Tokens: 190\n",
      "Prompt Tokens: 25\n",
      "Completion Tokens: 165\n",
      "Reasoning Tokens: 128\n",
      "Output Tokens: 62\n",
      "\n",
      "Response:\n",
      " There are 3 letter “p”s in the word “hippopotamus.”\n",
      ".........................\n"
     ]
    }
   ],
   "source": [
    "# Test o4mini\n",
    "response = o4mini_chat(\n",
    "    prompt=\"How many p's in hippopotamus?\",\n",
    "    reasoning_level=\"low\",\n",
    "    developer_message=\"You are a helpful assistant.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fd3791",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Let's Prompt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d7b58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................\n",
      "Response time: 3.86 seconds\n",
      "Total Tokens: 217\n",
      "Prompt Tokens: 38\n",
      "Completion Tokens: 179\n",
      "Reasoning Tokens: 64\n",
      "Output Tokens: 153\n",
      "\n",
      "Response:\n",
      " To find the time, use the relationship  \n",
      "   time = distance ÷ speed  \n",
      "\n",
      "Here, distance = 90 miles and speed = 60 miles per hour, so  \n",
      "   time = 90 miles ÷ 60 (miles/hour)  \n",
      "        = 1.5 hours  \n",
      "\n",
      "Since 0.5 hour = 30 minutes, 1.5 hours = 1 hour 30 minutes.  \n",
      "Answer: It takes 1 hour and 30 minutes.\n",
      ".........................\n",
      "To find the time, use the relationship  \n",
      "   time = distance ÷ speed  \n",
      "\n",
      "Here, distance = 90 miles and speed = 60 miles per hour, so  \n",
      "   time = 90 miles ÷ 60 (miles/hour)  \n",
      "        = 1.5 hours  \n",
      "\n",
      "Since 0.5 hour = 30 minutes, 1.5 hours = 1 hour 30 minutes.  \n",
      "Answer: It takes 1 hour and 30 minutes.\n"
     ]
    }
   ],
   "source": [
    "# -------------------\n",
    "# MATH EXAMPLE\n",
    "# -------------------\n",
    "response = o4mini_chat(\n",
    "    prompt=\"A train travels at 60 mph. How long does it take to travel 90 miles?\",\n",
    "    reasoning_level=\"low\",\n",
    "    developer_message=\"You are a math tutor. Explain the solution\"\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4e20849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................\n",
      "Response time: 3.95 seconds\n",
      "Total Tokens: 247\n",
      "Prompt Tokens: 38\n",
      "Completion Tokens: 209\n",
      "Reasoning Tokens: 128\n",
      "Output Tokens: 119\n",
      "\n",
      "Response:\n",
      " Let t = the number of apples Tom has.  \n",
      "Then Jane has 2t apples, and together:  \n",
      "t + 2t = 18  \n",
      "3t = 18  \n",
      "t = 6  \n",
      "\n",
      "So Tom has 6 apples, and Jane has 2·6 = 12 apples.\n",
      ".........................\n",
      "Let t = the number of apples Tom has.  \n",
      "Then Jane has 2t apples, and together:  \n",
      "t + 2t = 18  \n",
      "3t = 18  \n",
      "t = 6  \n",
      "\n",
      "So Tom has 6 apples, and Jane has 2·6 = 12 apples.\n"
     ]
    }
   ],
   "source": [
    "# -------------------\n",
    "#  MATH REASONING\n",
    "# -------------------\n",
    "prompt = \"Jane has twice as many apples as Tom. Together they have 18 apples. How many does each person have?\"\n",
    "response = o4mini_chat(prompt)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fb580ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................\n",
      "Response time: 13.93 seconds\n",
      "Total Tokens: 924\n",
      "Prompt Tokens: 33\n",
      "Completion Tokens: 891\n",
      "Reasoning Tokens: 512\n",
      "Output Tokens: 412\n",
      "\n",
      "Response:\n",
      " Even though both spoons are at “room temperature,” your skin feels them very differently simply because of how fast they conduct heat.  Here’s what’s going on:\n",
      "\n",
      "1. Thermal conductivity  \n",
      "   - Metals (e.g. steel, silver) have very high thermal conductivity.  Heat moves through them quickly.  \n",
      "   - Wood is a poor conductor (an insulator), so heat moves very slowly.\n",
      "\n",
      "2. Heat flow and what your nerves detect  \n",
      "   - When you touch an object warmer or cooler than your skin, heat will flow across that contact.  \n",
      "   - Thermoreceptors in your skin respond primarily to the rate of heat transfer, not just the temperature difference.  \n",
      "   - With the metal spoon, heat rushes out of your warm hand into the colder spoon faster, so your receptors register a strong “cold” sensation.  \n",
      "   - With the wooden spoon, heat still flows from your hand into the spoon, but far more slowly.  The spoon’s surface warms up under your finger almost as fast as you cool it, so you feel only a mild “cool” spot.\n",
      "\n",
      "3. Volumetric heat capacity (to a lesser extent)  \n",
      "   - Metals also tend to have high density and moderate specific heat, giving them a high volumetric heat capacity.  That means they can absorb a lot of heat from your hand without their own temperature changing much, sustaining the heat‐draw for longer.  \n",
      "   - Wood, by contrast, has a lower volumetric heat capacity, so its surface temperature rises quickly and the driving force for heat flow drops off.\n",
      "\n",
      "Bottom line:  “Coldness” on your skin is really a measure of how rapidly heat is stolen away.  Metal steals it fast, wood steals it slowly—so the metal spoon feels colder.\n",
      ".........................\n",
      "Even though both spoons are at “room temperature,” your skin feels them very differently simply because of how fast they conduct heat.  Here’s what’s going on:\n",
      "\n",
      "1. Thermal conductivity  \n",
      "   - Metals (e.g. steel, silver) have very high thermal conductivity.  Heat moves through them quickly.  \n",
      "   - Wood is a poor conductor (an insulator), so heat moves very slowly.\n",
      "\n",
      "2. Heat flow and what your nerves detect  \n",
      "   - When you touch an object warmer or cooler than your skin, heat will flow across that contact.  \n",
      "   - Thermoreceptors in your skin respond primarily to the rate of heat transfer, not just the temperature difference.  \n",
      "   - With the metal spoon, heat rushes out of your warm hand into the colder spoon faster, so your receptors register a strong “cold” sensation.  \n",
      "   - With the wooden spoon, heat still flows from your hand into the spoon, but far more slowly.  The spoon’s surface warms up under your finger almost as fast as you cool it, so you feel only a mild “cool” spot.\n",
      "\n",
      "3. Volumetric heat capacity (to a lesser extent)  \n",
      "   - Metals also tend to have high density and moderate specific heat, giving them a high volumetric heat capacity.  That means they can absorb a lot of heat from your hand without their own temperature changing much, sustaining the heat‐draw for longer.  \n",
      "   - Wood, by contrast, has a lower volumetric heat capacity, so its surface temperature rises quickly and the driving force for heat flow drops off.\n",
      "\n",
      "Bottom line:  “Coldness” on your skin is really a measure of how rapidly heat is stolen away.  Metal steals it fast, wood steals it slowly—so the metal spoon feels colder.\n"
     ]
    }
   ],
   "source": [
    "# -------------------\n",
    "#  SCIENCE REASONING\n",
    "# -------------------\n",
    "prompt = \"Why does a metal spoon feel colder than a wooden spoon when left in the same room?\"\n",
    "response = o4mini_chat(prompt)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6d52a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................\n",
      "Response time: 76.42 seconds\n",
      "Total Tokens: 1760\n",
      "Prompt Tokens: 36\n",
      "Completion Tokens: 1724\n",
      "Reasoning Tokens: 1024\n",
      "Output Tokens: 736\n",
      "\n",
      "Response:\n",
      " Here’s a simple 6‑week plan (Mon–Fri, 1 h/day = 30 h total) to get you from zero to a small Python project.\n",
      "\n",
      "Week 1 – Setup & Core Syntax  \n",
      " Mon 1: Install Python & IDE (VS Code, PyCharm or Thonny), run “Hello, world!”  \n",
      " Tue 2: Variables, basic data types (int, float, str, bool)  \n",
      " Wed 3: Numeric operations, type conversion, simple expressions  \n",
      " Thu 4: String basics: indexing, slicing, common methods (.upper, .split, f‑strings)  \n",
      " Fri 5: Hands‑on exercises (e.g. build a simple text‑based calculator)\n",
      "\n",
      "Week 2 – Control Flow  \n",
      " Mon 6: Boolean logic, comparison operators  \n",
      " Tue 7: if, elif, else statements  \n",
      " Wed 8: for loops (iterating lists, ranges)  \n",
      " Thu 9: while loops and loop control (break, continue)  \n",
      " Fri 10: Practice challenge (e.g. FizzBuzz, guessing game)\n",
      "\n",
      "Week 3 – Built‑in Data Structures  \n",
      " Mon 11: Lists: creation, indexing, methods (append, pop, sort)  \n",
      " Tue 12: Tuples & sets: when and how to use each  \n",
      " Wed 13: Dictionaries: key–value access, adding & removing entries  \n",
      " Thu 14: Comprehensions (list/dict/set) for concise loops  \n",
      " Fri 15: Mini project: word‑frequency counter or contact lookup\n",
      "\n",
      "Week 4 – Functions & Modules  \n",
      " Mon 16: Defining functions, parameters vs. arguments, return values  \n",
      " Tue 17: Variable scope, default args, *args & **kwargs  \n",
      " Wed 18: Exploring standard modules (math, random, datetime)  \n",
      " Thu 19: Creating & importing your own modules; pip & virtual environments  \n",
      " Fri 20: Practice: package up a small utility (e.g. temp converter module)\n",
      "\n",
      "Week 5 – File I/O & OOP Basics  \n",
      " Mon 21: File reading/writing (open, read, write, with‑statement)  \n",
      " Tue 22: Exception handling: try/except/finally, raising errors  \n",
      " Wed 23: Classes & objects: __init__, attributes, methods  \n",
      " Thu 24: Inheritance & simple magic methods (e.g. __str__)  \n",
      " Fri 25: Project: build a class‑based address book that reads/writes CSV\n",
      "\n",
      "Week 6 – Useful Libraries & Capstone Project  \n",
      " Mon 26: Working with JSON and REST APIs (using requests)  \n",
      " Tue 27: Intro to data libraries (NumPy arrays or basic Pandas DataFrame)  \n",
      " Wed 28: Quick look at virtual environments, packaging your project  \n",
      " Thu 29: Plan your final mini‑project (e.g. data fetcher, web scraper, CLI tool)  \n",
      " Fri 30: Build & polish your project; review key concepts and next steps\n",
      "\n",
      "Tips:  \n",
      " • Block out 5–10 min at the end of each session to recap.  \n",
      " • Use online docs (docs.python.org) or interactive tutorials (Codecademy, Repl.it).  \n",
      " • After Week 6, keep practicing by contributing to open‑source or building small utilities.  \n",
      "\n",
      "Good luck, and happy coding!\n",
      ".........................\n",
      "Here’s a simple 6‑week plan (Mon–Fri, 1 h/day = 30 h total) to get you from zero to a small Python project.\n",
      "\n",
      "Week 1 – Setup & Core Syntax  \n",
      " Mon 1: Install Python & IDE (VS Code, PyCharm or Thonny), run “Hello, world!”  \n",
      " Tue 2: Variables, basic data types (int, float, str, bool)  \n",
      " Wed 3: Numeric operations, type conversion, simple expressions  \n",
      " Thu 4: String basics: indexing, slicing, common methods (.upper, .split, f‑strings)  \n",
      " Fri 5: Hands‑on exercises (e.g. build a simple text‑based calculator)\n",
      "\n",
      "Week 2 – Control Flow  \n",
      " Mon 6: Boolean logic, comparison operators  \n",
      " Tue 7: if, elif, else statements  \n",
      " Wed 8: for loops (iterating lists, ranges)  \n",
      " Thu 9: while loops and loop control (break, continue)  \n",
      " Fri 10: Practice challenge (e.g. FizzBuzz, guessing game)\n",
      "\n",
      "Week 3 – Built‑in Data Structures  \n",
      " Mon 11: Lists: creation, indexing, methods (append, pop, sort)  \n",
      " Tue 12: Tuples & sets: when and how to use each  \n",
      " Wed 13: Dictionaries: key–value access, adding & removing entries  \n",
      " Thu 14: Comprehensions (list/dict/set) for concise loops  \n",
      " Fri 15: Mini project: word‑frequency counter or contact lookup\n",
      "\n",
      "Week 4 – Functions & Modules  \n",
      " Mon 16: Defining functions, parameters vs. arguments, return values  \n",
      " Tue 17: Variable scope, default args, *args & **kwargs  \n",
      " Wed 18: Exploring standard modules (math, random, datetime)  \n",
      " Thu 19: Creating & importing your own modules; pip & virtual environments  \n",
      " Fri 20: Practice: package up a small utility (e.g. temp converter module)\n",
      "\n",
      "Week 5 – File I/O & OOP Basics  \n",
      " Mon 21: File reading/writing (open, read, write, with‑statement)  \n",
      " Tue 22: Exception handling: try/except/finally, raising errors  \n",
      " Wed 23: Classes & objects: __init__, attributes, methods  \n",
      " Thu 24: Inheritance & simple magic methods (e.g. __str__)  \n",
      " Fri 25: Project: build a class‑based address book that reads/writes CSV\n",
      "\n",
      "Week 6 – Useful Libraries & Capstone Project  \n",
      " Mon 26: Working with JSON and REST APIs (using requests)  \n",
      " Tue 27: Intro to data libraries (NumPy arrays or basic Pandas DataFrame)  \n",
      " Wed 28: Quick look at virtual environments, packaging your project  \n",
      " Thu 29: Plan your final mini‑project (e.g. data fetcher, web scraper, CLI tool)  \n",
      " Fri 30: Build & polish your project; review key concepts and next steps\n",
      "\n",
      "Tips:  \n",
      " • Block out 5–10 min at the end of each session to recap.  \n",
      " • Use online docs (docs.python.org) or interactive tutorials (Codecademy, Repl.it).  \n",
      " • After Week 6, keep practicing by contributing to open‑source or building small utilities.  \n",
      "\n",
      "Good luck, and happy coding!\n"
     ]
    }
   ],
   "source": [
    "# -------------------\n",
    "#  MULTI-STEP PLANNING\n",
    "# -------------------\n",
    "prompt = \"Design a basic weekly study schedule to learn Python in 6 weeks, assuming 1 hour per weekday.\"\n",
    "response = o4mini_chat(prompt)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cba29ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................\n",
      "Response time: 17.66 seconds\n",
      "Total Tokens: 871\n",
      "Prompt Tokens: 59\n",
      "Completion Tokens: 812\n",
      "Reasoning Tokens: 704\n",
      "Output Tokens: 167\n",
      "\n",
      "Response:\n",
      " Here’s one way to satisfy all the constraints (each works a single 4‑hour block, only Alex/Riley ever work before 12, and Sam finishes by 4 PM):\n",
      "\n",
      "• 8:00 AM – 12:00 PM: Alex  \n",
      "• 12:00 PM – 4:00 PM: Sam  \n",
      "• 4:00 PM – 8:00 PM: Riley\n",
      ".........................\n",
      "Here’s one way to satisfy all the constraints (each works a single 4‑hour block, only Alex/Riley ever work before 12, and Sam finishes by 4 PM):\n",
      "\n",
      "• 8:00 AM – 12:00 PM: Alex  \n",
      "• 12:00 PM – 4:00 PM: Sam  \n",
      "• 4:00 PM – 8:00 PM: Riley\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------\n",
    "# CONSTRAINT-BASED SCHEDULING\n",
    "# --------------------------------\n",
    "prompt = \"Three employees—Alex, Sam, and Riley—must each work one 4-hour shift today. Only Alex and Riley can work before noon, and Sam can’t work past 4 PM. Create a valid schedule.\"\n",
    "response = o4mini_chat(prompt)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3f9135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------\n",
    "# TRY YOUR OWN\n",
    "# -------------------\n",
    "\n",
    "# Write your own prompt here\n",
    "prompt = \"\"  \n",
    "\n",
    "# Change these if you want to experiment\n",
    "reasoning_level = \"medium\"\n",
    "developer_message = \"You are a helpful assistant.\"\n",
    "response = o4mini_chat(prompt, reasoning_level, developer_message)\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
