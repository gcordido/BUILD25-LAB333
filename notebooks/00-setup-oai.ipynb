{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c43f9bf9",
   "metadata": {},
   "source": [
    "# Validate Open AI Setup\n",
    "\n",
    "This notebook guides you through validating your OpenAI environment. The sections below:\n",
    "\n",
    "- **Install Required Packages:** Ensure all necessary Python packages are installed for OpenAI and environment management.\n",
    "- **Check Environment Variables:** Verify that all required OpenAI environment variables are set for secure and successful API access.\n",
    "- **Utility Functions:** Provide helper functions for pretty-printing token usage and content filter results from API responses.\n",
    "- **Initialize OpenAI Client:** Set up the OpenAI client using your environment variables for authenticated API calls.\n",
    "- **Run Sample Queries:** Demonstrate how to send test prompts to your OpenAI deployment and display the results, confirming your setup is working correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44927c14",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Install Python Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc8b8ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install prerequisites (quiet)\n",
    "!pip install -q openai python-dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c694a8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Check Environment Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fff827db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OPENAI_API_KEY detected.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"Validate OPENAI_API_KEY in environment or .env file.\"\"\"\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\n",
    "        \"‚ùå OPENAI_API_KEY not found. Create a .env file with OPENAI_API_KEY=your_key\"\n",
    "    )\n",
    "print(\"‚úÖ OPENAI_API_KEY detected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4266ff5b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Utility Function: Print Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dca1f259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretty print some information\n",
    "def print_token_info(r):\n",
    "    # Print token usage\n",
    "    print(\".........................\")\n",
    "    print(\"Token Costs:\")\n",
    "    print(f\"Total Tokens: {r.usage.total_tokens}\")\n",
    "    print(f\"Prompt Tokens: {r.usage.prompt_tokens}\")\n",
    "    print(f\"Completion Tokens: {r.usage.completion_tokens}\")\n",
    "    print(f\"Reasoning Tokens: {r.usage.completion_tokens_details.reasoning_tokens}\")\n",
    "    print(f\"Output Tokens: {r.usage.total_tokens - r.usage.completion_tokens_details.reasoning_tokens}\")\n",
    "    print(\".........................\")\n",
    "\n",
    "    # Print content filter results\n",
    "    print(\"Content Filter Results:\")\n",
    "    filter_results = getattr(r.choices[0], \"content_filter_results\", None)\n",
    "    if filter_results is not None:\n",
    "        for k, v in filter_results.items():\n",
    "            print(f\"{k}: {v}\")\n",
    "    else:\n",
    "        print(\"No content filter results available.\")\n",
    "    print(\".........................\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74df1878",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def chat(model:str, prompt:str=\"Hello!\", **kwargs):\n",
    "    \"\"\"Pretty chat helper.\"\"\"\n",
    "    r = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\":\"user\",\"content\":prompt}],\n",
    "        **kwargs\n",
    "    )\n",
    "    print(f\"üó£Ô∏è {model} returned:\")\n",
    "    print(r.choices[0].message.content)\n",
    "    print_token_info(r)\n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff86458",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## 5. Test with General Purpose Model\n",
    "\n",
    "- Observe the time taken to execute the call.\n",
    "- Note the accuracy of the response\n",
    "- Note the Total tokens used\n",
    "- Note the Reasoning token contribution to this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d729388f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üó£Ô∏è gpt-4o-mini returned:\n",
      "There are three 'r's in the word \"strawberry.\"\n",
      ".........................\n",
      "Token Costs:\n",
      "Total Tokens: 29\n",
      "Prompt Tokens: 14\n",
      "Completion Tokens: 15\n",
      "Reasoning Tokens: 0\n",
      "Output Tokens: 29\n",
      ".........................\n",
      "Content Filter Results:\n",
      "No content filter results available.\n",
      ".........................\n"
     ]
    }
   ],
   "source": [
    "response = chat(os.getenv(\"GENERAL_PURPOSE\"), \"How many r's in strawberry?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab75cb97",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "## 6. Test With Reasoning Model (old)\n",
    "\n",
    "- Observe the time taken to execute the call.\n",
    "- Note the accuracy of the response\n",
    "- Note the Total tokens used\n",
    "- Note the Reasoning token contribution to this\n",
    "- **How does this compare to the GPT model?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71ebe379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üó£Ô∏è o1 returned:\n",
      "There are 3 \"r\"s in the word \"strawberry.\"\n",
      ".........................\n",
      "Token Costs:\n",
      "Total Tokens: 167\n",
      "Prompt Tokens: 13\n",
      "Completion Tokens: 154\n",
      "Reasoning Tokens: 128\n",
      "Output Tokens: 39\n",
      ".........................\n",
      "Content Filter Results:\n",
      "No content filter results available.\n",
      ".........................\n"
     ]
    }
   ],
   "source": [
    "response = chat(os.getenv(\"REASONING_OLD\"), \"How many r's in strawberry?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c467a8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Test with Reasoning Model (new)\n",
    "\n",
    "- Observe the time taken to execute the call.\n",
    "- Note the accuracy of the response\n",
    "- Note the Total tokens used\n",
    "- Note the Reasoning token contribution to this\n",
    "- **How does this compare to the GPT and older Reasoning models?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0f55c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üó£Ô∏è o4-mini returned:\n",
      "There are three ‚Äúr‚Äù letters in the word ‚Äústrawberry.‚Äù\n",
      ".........................\n",
      "Token Costs:\n",
      "Total Tokens: 495\n",
      "Prompt Tokens: 13\n",
      "Completion Tokens: 482\n",
      "Reasoning Tokens: 448\n",
      "Output Tokens: 47\n",
      ".........................\n",
      "Content Filter Results:\n",
      "No content filter results available.\n",
      ".........................\n"
     ]
    }
   ],
   "source": [
    "response = chat(os.getenv(\"REASONING_NEW\"), \"How many r's in strawberry?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15aad80",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Congratulations\n",
    "\n",
    "You're all set for the labs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
